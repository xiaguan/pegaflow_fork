#!/usr/bin/env python3
"""PegaEngine Server - Independent process for KV cache management.

This server runs as a separate process from vLLM and handles GPU KV cache
operations via CUDA IPC. It receives tensor IPC handles from vLLM, reconstructs
the tensors, and uses the Rust PegaEngine backend for efficient storage/retrieval.

Architecture:
    vLLM Process                    Engine Server Process
    ┌──────────────┐               ┌──────────────────┐
    │ Connector    │  ─── ZMQ ──→  │ ZMQ Server       │
    │ (Client)     │  ← Request →  │ + PegaEngine     │
    └──────────────┘               └──────────────────┘
         ↓                                  ↓
    GPU Tensor ────── CUDA IPC ────→ Reconstructed Tensor
                    (shared memory)         ↓
                                      tensor.data_ptr()
                                            ↓
                                      Rust PegaEngine

Protocol:
    Request:  (command: str, payload: dict)
    Response: (status: str, result: Any)

Commands:
    - REGISTER_CONTEXT: Register KV cache layer from IPC handle
    - SAVE: Save blocks to CPU storage
    - LOAD: Load blocks to GPU
    - QUERY: Query cache hit count
    - UNREGISTER_CONTEXT: Clear registered context and release tensors
    - SHUTDOWN: Clean shutdown
"""

import argparse
import logging
import os
import pickle
import signal
import sys
from dataclasses import dataclass, field
from typing import Any, Dict, Optional

import msgpack
import torch
import zmq

from pegaflow.pegaflow import PegaEngine

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


@dataclass
class _ContextState:
    device_id: int
    tensors: Dict[str, torch.Tensor] = field(default_factory=dict)


class CudaIPCWrapper:
    """Wrapper for CUDA IPC handle with tensor metadata.

    This is a copy of the class from ipc_wrapper.py to avoid import issues.
    """

    def __init__(self, tensor: torch.Tensor):
        assert tensor.storage_offset() == 0, "Tensor must have zero storage offset"
        assert tensor.is_contiguous(), "Tensor must be contiguous"

        storage = tensor.untyped_storage()
        handle = storage._share_cuda_()

        self.handle = handle
        self.dtype = tensor.dtype
        self.shape = tensor.shape
        self.device = tensor.device.index

    def to_tensor(self) -> torch.Tensor:
        """Reconstruct tensor from IPC handle."""
        storage = torch.UntypedStorage._new_shared_cuda(*self.handle)
        device = self.handle[0]
        t = torch.tensor([], device=device, dtype=self.dtype)
        t.set_(storage)
        return t.view(self.shape)


class PegaEngineServer:
    """ZMQ server wrapping Rust PegaEngine for cross-process KV cache access."""

    def __init__(self, socket_path: str, device: int = 0):
        """Initialize the engine server.

        Args:
            socket_path: ZMQ socket endpoint (e.g., "ipc:///tmp/pega_engine.sock")
            device: CUDA device index
        """
        self.socket_path = socket_path
        self.default_device = device

        # Initialize CUDA
        torch.cuda.init()
        torch.cuda.set_device(device)
        logger.info("Initialized default CUDA device %d", device)

        # Initialize Rust PegaEngine
        self.engine = PegaEngine()
        logger.info("Initialized PegaEngine")

        # Store reconstructed tensors per context to keep them alive
        self._contexts: Dict[str, _ContextState] = {}

        # ZMQ setup
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REP)

        # Clean up existing IPC socket if needed
        if socket_path.startswith("ipc://"):
            ipc_path = socket_path.replace("ipc://", "")
            try:
                os.unlink(ipc_path)
            except FileNotFoundError:
                pass

        self.socket.bind(socket_path)
        logger.info("ZMQ server bound to %s", socket_path)

        self.running = False

    def _require_instance_id(self, payload: Dict[str, Any]) -> str:
        instance_id = payload.get("instance_id") or payload.get("context_id")
        if not instance_id:
            raise ValueError("instance_id not provided in payload")
        return str(instance_id)

    def _require_tp_rank(self, payload: Dict[str, Any]) -> int:
        # If tp_rank is explicitly provided (e.g. from scheduler query?), use it.
        # Otherwise handle missing case gracefully if possible or raise.
        rank = payload.get("tp_rank")
        if rank is None:
             # Fallback/Error handling? Assuming strictly required for worker ops.
             # For QUERY from scheduler, it might be missing, but QUERY doesn't need tp_rank now.
             raise ValueError("tp_rank not provided in payload")
        return int(rank)

    def _get_or_create_context(
        self,
        context_key: str,
        device_id: Optional[int],
    ) -> _ContextState:
        if context_key in self._contexts:
            state = self._contexts[context_key]
            if device_id is not None and state.device_id != device_id:
                raise ValueError(
                    f"Context {context_key} already bound to device {state.device_id}, got {device_id}"
                )
            return state

        resolved_device = device_id if device_id is not None else self.default_device
        state = _ContextState(device_id=resolved_device)
        self._contexts[context_key] = state
        return state

    def _drop_context(self, context_key: str) -> None:
        state = self._contexts.pop(context_key, None)
        if state:
            state.tensors.clear()

    def _handle_register_context(self, payload: dict) -> dict:
        """Handle REGISTER_CONTEXT command - register KV cache from IPC handle.

        Args:
            payload: {
                'layer_name': str,
                'wrapper_bytes': bytes,  # pickled CudaIPCWrapper
                'num_blocks': int,
                'bytes_per_block': int,
                'kv_stride_bytes': int,
                'segments': int,
                'tp_rank': int,
                'tp_size': int,
                'num_layers': int,
            }

        Returns:
            {'status': 'success'} or {'status': 'error', 'message': str}
        """
        try:
            instance_id = self._require_instance_id(payload)
            tp_rank = self._require_tp_rank(payload)

            layer_name = payload['layer_name']
            wrapper_bytes = payload['wrapper_bytes']
            num_blocks = payload['num_blocks']
            bytes_per_block = payload['bytes_per_block']
            kv_stride_bytes = payload['kv_stride_bytes']
            segments = payload['segments']
            device_id = payload.get('device_id')

            # Topology info
            tp_size = payload['tp_size']
            num_layers = payload['num_layers']

            # Use (instance_id, tp_rank) as key for keeping tensors alive in Python process
            context_key = f"{instance_id}:tp{tp_rank}"
            state = self._get_or_create_context(context_key, device_id)

            # Ensure CUDA operations run on the correct device
            torch.cuda.set_device(state.device_id)

            # Reconstruct tensor from IPC handle
            wrapper = pickle.loads(wrapper_bytes)
            tensor = wrapper.to_tensor()

            # Store tensor reference to keep GPU memory alive
            state.tensors[layer_name] = tensor

            # Register with Rust PegaEngine using raw pointer
            data_ptr = tensor.data_ptr()
            size_bytes = tensor.untyped_storage().nbytes()

            self.engine.register_context_layer(
                instance_id,
                state.device_id,
                layer_name,
                data_ptr,
                size_bytes,
                num_blocks,
                bytes_per_block,
                kv_stride_bytes,
                segments,
                tp_rank,
                tp_size,
                num_layers,
            )

            logger.info(
                "Registered layer '%s' for instance %s rank %d (device %d): ptr=0x%x",
                layer_name, instance_id, tp_rank, state.device_id, data_ptr
            )

            return {'status': 'success'}

        except Exception as e:
            logger.error("Failed to register context layer: %s", e, exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def _handle_unregister_context(self, payload: dict) -> dict:
        """Handle UNREGISTER_CONTEXT command - clear registered context."""
        try:
            instance_id = self._require_instance_id(payload)
            
            # Clean up python side resources for all known ranks of this instance?
            # Currently we track keys as "{instance_id}:tp{rank}"
            keys_to_drop = [k for k in self._contexts.keys() if k.startswith(f"{instance_id}:")]
            for k in keys_to_drop:
                self._drop_context(k)

            self.engine.unregister_instance(instance_id)
            logger.info("Unregistered instance %s", instance_id)
            return {'status': 'success'}
        except Exception as e:
            logger.error("Failed to unregister instance: %s", e, exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def _handle_save(self, payload: dict) -> dict:
        """Handle SAVE command - save blocks to CPU storage.

        Args:
            payload: {
                'layer_name': str,
                'block_ids': list[int],
                'block_hashes': list[bytes],
            }

        Returns:
            {'status': 'success'} or {'status': 'error', 'message': str}
        """
        try:
            instance_id = self._require_instance_id(payload)
            tp_rank = self._require_tp_rank(payload)
            layer_name = payload['layer_name']
            block_ids = payload['block_ids']
            block_hashes = payload['block_hashes']

            self.engine.save_kv_blocks_from_ipc(
                instance_id,
                tp_rank,
                layer_name,
                block_ids,
                block_hashes
            )

            logger.debug(
                "Saved %d blocks for layer '%s' (instance %s rank %d)",
                len(block_ids), layer_name, instance_id, tp_rank
            )

            return {'status': 'success'}

        except Exception as e:
            logger.error("Failed to save blocks: %s", e, exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def _handle_load(self, payload: dict) -> dict:
        """Handle LOAD command - batch load blocks to GPU.

        Args:
            payload: {
                'load_state_shm': str,  # shared memory name for LoadState sync
                'layer_names': list[str],
                'block_ids': list[int],
                'block_hashes': list[bytes],
            }

        Returns:
            {'status': 'success'} or {'status': 'error', 'message': str}
        """
        try:
            instance_id = self._require_instance_id(payload)
            tp_rank = self._require_tp_rank(payload)
            load_state_shm = payload['load_state_shm']
            layer_names = payload['layer_names']
            block_ids = payload['block_ids']
            block_hashes = payload['block_hashes']

            self.engine.batch_load_kv_blocks(
                instance_id,
                tp_rank,
                load_state_shm,
                layer_names,
                block_ids,
                block_hashes
            )

            logger.debug(
                "Submitted load for %d blocks across %d layers for instance %s rank %d",
                len(block_ids), len(layer_names), instance_id, tp_rank
            )

            return {'status': 'success'}

        except Exception as e:
            logger.error("Failed to load blocks: %s", e, exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def _handle_query(self, payload: dict) -> dict:
        """Handle QUERY command - count available blocks.

        Args:
            payload: {
                'block_hashes': list[bytes],
            }

        Returns:
            {'status': 'success', 'hit_blocks': int}
            or {'status': 'error', 'message': str}
        """
        try:
            block_hashes = payload['block_hashes']

            hit_blocks = self.engine.count_prefix_hit_blocks(block_hashes)

            return {
                'status': 'success',
                'hit_blocks': hit_blocks,
            }

        except Exception as e:
            logger.error("Failed to query blocks: %s", e, exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def _handle_shutdown(self, payload: dict) -> dict:
        """Handle SHUTDOWN command - graceful shutdown."""
        logger.info("Received shutdown command")
        for context_key in list(self._contexts.keys()):
            self._drop_context(context_key)

        # Unregister all instances from engine
        # (We don't have a method to list all instances from engine,
        # but we cleared Python-side contexts. Rust side might still have data.
        # Ideally we should clear engine too, but maybe not needed for hard shutdown)

        self.running = False
        return {'status': 'success'}

    def run(self):
        """Main server loop - receive and handle requests."""
        self.running = True
        logger.info("PegaEngine server running, waiting for requests...")

        while self.running:
            try:
                # Receive request using multipart: [command, payload]
                message_parts = self.socket.recv_multipart()

                if len(message_parts) != 2:
                    raise ValueError(f"Invalid request format: expected 2 parts, got {len(message_parts)}")

                # Deserialize command and payload
                command = msgpack.unpackb(message_parts[0], raw=False)
                payload = msgpack.unpackb(message_parts[1], raw=False)

                # Dispatch command
                if command in ('REGISTER', 'REGISTER_CONTEXT'):
                    response = self._handle_register_context(payload)
                elif command in ('UNREGISTER', 'UNREGISTER_CONTEXT'):
                    response = self._handle_unregister_context(payload)
                elif command == 'SAVE':
                    response = self._handle_save(payload)
                elif command == 'LOAD':
                    response = self._handle_load(payload)
                elif command == 'QUERY':
                    response = self._handle_query(payload)
                elif command == 'SHUTDOWN':
                    response = self._handle_shutdown(payload)
                else:
                    response = {
                        'status': 'error',
                        'message': f'Unknown command: {command}'
                    }

                # Send response using multipart
                response_bytes = msgpack.packb(response, use_bin_type=True)
                self.socket.send_multipart([response_bytes])

            except zmq.ZMQError as e:
                if not self.running:
                    break
                logger.error("ZMQ error: %s", e)
            except Exception as e:
                logger.error("Error handling request: %s", e, exc_info=True)
                # Send error response
                try:
                    response = {'status': 'error', 'message': str(e)}
                    response_bytes = msgpack.packb(response, use_bin_type=True)
                    self.socket.send_multipart([response_bytes])
                except Exception:
                    pass

        logger.info("Server loop exited")

    def shutdown(self):
        """Clean shutdown - close sockets and cleanup resources."""
        logger.info("Shutting down server...")
        self.running = False

        # Unregister all KV caches
        for context_key in list(self._contexts.keys()):
            self._drop_context(context_key)

        # Close ZMQ socket
        try:
            self.socket.close()
        except Exception as e:
            logger.error("Error closing socket: %s", e)

        # Terminate ZMQ context
        try:
            self.context.term()
        except Exception as e:
            logger.error("Error terminating context: %s", e)

        logger.info("Server shutdown complete")


def main():
    parser = argparse.ArgumentParser(description='PegaEngine Server')
    parser.add_argument(
        '--socket',
        type=str,
        default='ipc:///tmp/pega_engine.sock',
        help='ZMQ socket path (default: ipc:///tmp/pega_engine.sock)'
    )
    parser.add_argument(
        '--device',
        type=int,
        default=0,
        help='CUDA device index (default: 0)'
    )
    args = parser.parse_args()

    # Create server
    server = PegaEngineServer(socket_path=args.socket, device=args.device)

    # Handle signals for graceful shutdown
    def signal_handler(sig, frame):
        logger.info("Received signal %d, shutting down...", sig)
        server.shutdown()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Run server
    try:
        server.run()
    except Exception as e:
        logger.error("Server error: %s", e, exc_info=True)
    finally:
        server.shutdown()


if __name__ == '__main__':
    main()
